为什么 AI Agent 需要浏览器能力
大语言模型的知识有截止日期，无法访问实时信息。当你让 Agent 帮你查最新的 GitHub Trending、读某条 X 帖子的评论、或者从 SEC EDGAR 拉财报数据时，它需要一双"眼睛"——浏览器。
但传统的浏览器自动化（Selenium、Puppeteer）要么写脚本太繁琐，要么让 LLM 自己摸索页面结构（慢、贵、不稳定）。这就是为什么需要专门为 AI Agent 设计的浏览器工具：
agent-browser 提供无头浏览器 + 可访问性树（accessibility tree）
actionbook 用预计算的"操作手册"告诉 Agent 怎么操作网站
browser-use 则是 Python 库封装的高级抽象
这三个工具各有侧重，组合使用能覆盖从轻量级信息读取到复杂交互的全场景。
工具对比
快速上手：agent-browser
安装
npm i -g agent-browser
预期输出：安装完成后运行 agent-browser --version 应显示版本号（如 0.9.2）。
实战例子 1：读取 X/Twitter 帖子内容
无需登录，可获取完整内容 + 互动数据（点赞、转发、回复数）。
# 打开 X 帖子
agent-browser open "https://x.com/elonmusk/status/1234567890"
​
# 获取可访问性树（带 refs）
agent-browser snapshot --compact
​
# 提取特定元素文本（假设帖子主体是 e5）
agent-browser get text e5
​
# 关闭浏览器
agent-browser close
预期输出：
snapshot 会输出页面的可访问性树，每个可交互元素有一个 e1、e2 这样的引用（ref）
注意：refs 是 e1 格式，不是 @e1
get text e5 会返回该元素的文本内容
实测发现：agent-browser 读 X 长文无需登录，比浏览器自动化更稳定。
实战例子 2：读取 GitHub 仓库信息
agent-browser open "https://github.com/trending"
agent-browser snapshot --compact
预期输出：
可访问性树会列出 Trending 页面的所有仓库链接、Star 数、描述等
通过解析 refs 可以提取结构化数据
实战例子 3：截取网页截图
agent-browser open "https://github.com/trending"
agent-browser screenshot github-trending.png
预期输出：
生成 github-trending.png 文件
实测截图 GitHub Trending 页面约 99KB
提示：截图完记得 agent-browser close 释放浏览器进程。
快速上手：行动书
安装
npm i -g @actionbookdev/cli
预期输出：运行 actionbook --version 应显示版本号（如 0.6.2）。
操作手册演示
1. 查看支持的网站列表
actionbook sources list
预期输出：
x.com
reddit.com
scholar.google.com
sec.gov
crunchbase.com
...
（50+ 网站）
这些网站已有预计算的"操作手册"，Agent 不需要猜页面结构。
2. 搜索操作手册
actionbook search "post tweet"
预期输出：
x.com:/:default - Post a tweet on X
x.com:/compose/tweet:default - Compose tweet interface
...
返回相关的操作手册 ID。
3. 获取完整操作手册
actionbook get "x.com:/:default"
预期输出：
{
  "id": "x.com:/:default",
  "url": "https://x.com",
  "actions": [
    {
      "name": "post_tweet",
      "steps": [
        { "type": "click", "selector": "[data-testid='SideNav_NewTweet_Button']" },
        { "type": "fill", "selector": "[data-testid='tweetTextarea_0']", "value": "{{text}}" },
        { "type": "click", "selector": "[data-testid='tweetButtonInline']" }
      ]
    }
  ]
}
手册里清楚写明每一步操作：点哪里、填什么、等什么。Agent 直接执行，不用 LLM 猜测。
两者配合使用的场景
场景 1：读取 + 操作
agent-browser 打开页面，snapshot 获取当前状态
actionbook 查询操作手册，执行标准化操作（如发帖、点赞）
agent-browser 再次 snapshot 确认作结果
示例：自动回复 X 提到你的帖子
agent-browser 打开通知页面，读取提到列表
actionbook 执行 x.com:/reply:default 手册，回复特定帖子
agent-browser 截图存档
场景 2：已支持 vs. 未支持网站
已有 actionbook 手册的网站（X, Reddit, Google Scholar）：优先用 actionbook（快、便宜、稳定）
未支持的网站：用 agent-browser 读取 + LLM 解析可访问性树
场景 3：Google 搜索的坑
注意：Google 会检测机器人 IP，VPS 上跑 agent-browser/actionbook 搜索 Google 大概率被拦截。这是正常的，不是工具问题。
解决方案：
用 Google Custom Search API（官方接口）
或者用 Brave Search API（OpenClaw 内置的 web_search 工具）
或者在本地机器跑浏览器（IP 相对干净）
VPS/Linux 无桌面环境部署指南
agent-browser 和 actionbook 都基于 Playwright Chromium，原生支持 headless 模式，无需 X11 或图形界面。
系统依赖（Ubuntu/Debian）
# 安装 Node.js（如果没有）
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt-get install -y nodejs

# 安装 Chromium 依赖
sudo apt-get install -y \
  libnss3 libatk1.0-0 libatk-bridge2.0-0 libcups2 \
  libdrm2 libxkbcommon0 libxcomposite1 libxdamage1 \
  libxfixes3 libxrandr2 libgbm1 libasound2
安装工具
npm i -g agent-browser @actionbookdev/cli
测试运行
# agent-browser 默认就是 headless
agent-browser open "https://example.com"
agent-browser screenshot test.png
agent-browser close

# actionbook 需要显式指定 --headless
actionbook --headless browser open "https://example.com"
预期输出：
不会报 Error: No display
截图正常生成
常见问题
问题 ：错误：/root/.cache/ms-playwright/chromium-xxxx/chrome-linux/chrome 不存在可执行文件
解决：
npx playwright install chromium
npx playwright install-deps chromium
与 OpenClaw 集成
OpenClaw 的 nodes 工具允许你在远程机器（VPS）上运行命令，并把结果返回给本地 Agent。
前提条件
VPS 已安装 OpenClaw Node 客户端并配对
VPS 已安装 agent-browser / actionbook
远程调用示例
假设你的 VPS 节点名叫 vps-worker。
用 agent-browser 读取 X 帖子
# 在本地 OpenClaw 主机运行
openclaw nodes run vps-worker -- bash -c "
  agent-browser open 'https://x.com/sama/status/1234567890' && \
  agent-browser snapshot --compact && \
  agent-browser close
"
预期输出：VPS 上执行命令，返回可访问性树到本地终端。
用 actionbook 查询手册
openclaw nodes run vps-worker -- actionbook search "reddit post"
预期输出：返回 Reddit 相关的操作手册列表。
OpenClaw Agent 内调用（通过 nodes tool）
在 OpenClaw 的 Agent 对话中：
请帮我截图 GitHub Trending 页面
Agent 会自动调用：
nodes(
  action="run",
  node="vps-worker",
  command=["bash", "-c", "agent-browser open 'https://github.com/trending' && agent-browser screenshot trending.png && cat trending.png | base64"]
)
然后把 base64 编码的截图解码保存到本地。
为什么要远程调用？
VPS IP 更干净：某些网站检测家庭宽带 IP（如 Google）
分离计算负载：本地机器专注 LLM 推理，浏览器任务丢给远程
多节点并行：同时让多个 VPS 各自抓取不同网站
总结
实战建议：
优先查 actionbook sources list，有手册就用手册（省钱省时间）
没手册的网站用 agent-browser 读取 + LLM 解析
Google 搜索别用浏览器，用 API（Brave Search / Google 自定义搜索）
VPS 部署记得装 Chromium 依赖，测试 headless 模式
OpenClaw 集成时用 nodes run 远程调用，结果自动返回本地
下一步：
试试在本地跑 agent-browser 读你最近收藏的 X 帖子
用 actionbook search 查你常用网站有没有现成手册
如果有 VPS，部署一个远程 worker 节点给 OpenClaw 调用